---
layout: default
---

<body>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!--<center> <h1>Statistics, Psychometrics, Games</h1> </center>
<center> <h3>Harold Doran</h3> </center> -->

<center> <h1> Dictionary Problem </h1> </center>

<h2> Problem Statement </h2> 
<h3>
<p>
The dictionary problem as stated <a href = "https://fivethirtyeight.com/features/can-you-break-a-very-expensive-centrifuge/" target = "blank"> here </a> is summarized as:

"Each secret word is randomly chosen from a dictionary with exactly 267,751 entries. If you have this dictionary memorized, and play the game as efficiently as possible, how many guesses should you expect to make to guess the secret word?" <b> The answer is 17.04 with a maximum number of required guesses being 19. </b>
</p>
</h3>

<h2> Motivating Example </h2>
<h3>
<p>
The solution is motivated by a simple example using a <a href = "https://en.wikipedia.org/wiki/Binary_search_algorithm" target="_blank"> binary search algorithm </a> to consider how we might work efficiently. To illustrate, I pick a random number from 1 to 15 and ask you to guess the number I am thinking. I will tell you if it's higher, lower, or correct. You first guess the midpoint, 8, which has a \(\frac{1}{15}\) chance of being correct. If the number is higher you can eliminate numbers 1 to 8 (or vice versa if the number is lower) and guess two has a \(\frac{1}{7}\) chance of being correct by focusing on the new region of the sequence (i.e., numbers 9 through 15). If a guess 3 is needed, find the midpoint in the remaining sequence and the success probability becomes \(\frac{1}{3}\). Last, guess 4 (if needed) has only one remaining possible choice, hence the success probability at this point is 1. Using this strategy with a sequence of size 15, you would need a maximum of 4 attempts to identify the number with certainty.
</p>

<p>
So, by iteratively halving the sequence and reducing the search space in the region where the number exists, we continue to improve the probability of success until we ultimately reach a point of certainty. This illustrates a way to work efficiently and a model for estimating the maximum number of guesses we would need to find a solution. However, we won't always need the maximum number of guesses as other values less than the maximum have non-zero probabilities, but this helps conceptualize the problem to work towards a solution for the expected value.
</p>

<p>
Combining these pieces of information, we can find the expected value for the number of guesses, \(E(G)\), by using the probabilities of being right or wrong at each possible guess, 1 through the maximum. In this example, we can write:

$$
E(G) = 1 \cdot \frac{1}{15} + 2 \cdot \frac{14}{15}\frac{1}{7} + 3 \cdot \frac{14}{15}\frac{6}{7}\frac{1}{3} + 4 \cdot \frac{14}{15}\frac{6}{7}\frac{2}{3}1 = 3.266
$$

This example shows that piecing this together requires knowing:
<ul>
	<li> The maximum number of guesses needed
	<li> The probability of being right at each guess
	<li> The accumulated probabilities of being wrong for all guesses prior to the \(n\)th guess
</ul>
</p>

To establish a little notation for the preceding example, let \(\Pr(x=1|g_n)\) denote the success probability at the \(n\)th guess and let \(\Pr(x=0|g_n)\) denote the probability of being wrong at the \(n\)th guess. Then the expected value for the number of guesses in this example can be written as:

$$
\begin{split}
E(G) & = 1 \cdot \Pr(x=1|g_1) \\ 
	& +  2 \cdot \Pr(x=0|g_1)\Pr(x=1|g_2) \\  
	& + 3 \cdot \Pr(x=0|g_1)\Pr(x=0|g_2)\Pr(x=1|g_3) \\ 
	& + 4 \cdot \Pr(x=0|g_1)\Pr(x=0|g_2)\Pr(x=0|g_3)\Pr(x=1|g_4)
\end{split}
$$

<h2> Towards a Solution </h2>
<h3>

<p>
Knowing that our success probability tends to 1 using this strategy, finding a general solution requires building a model that makes use of this efficient strategy. For completeness, first find the maximum number of times a sequence of size \(k\) can be halved: 

$$
L = \textrm{floor}\left(\frac{\log(k)}{\log(2)}\right)
$$ 

and then generally the maximum number of guesses needed to locate the correct answer in a sequence of size \(k\) is \(N = 1 + L\), or initial guess plus remaining number of times the sequence can be halved. Then, generalizing to find the expected value over an arbitrary sequence of length \(k\):

$$
E(G) = \Pr(x=1|g_1) + \sum_{n=2}^N \left(n \cdot \Pr(x=1|g_n) \prod_{j \in a}\Pr(x=0|g_j)\right)
$$

where the notation \(j \in a\) is used to mean the accumulated set of incorrect probabilities preceding the \(n\)th guess which can be computed by recursion.

</p>

<p>
Applying this to the dictionary problem with a dictionary consisting of 267,751 words yields an expected <b> maximum </b> number of guesses:

$$
\textrm{floor}\left(\frac{\log(267751)}{\log(2)}\right) + 1 = 19.
$$ 
</p>

<p>
However, guessing the secret word could happen in fewer than 19 guesses. We can apply the expression above to find \(E(G) = 17.04\). Additionally, we can simulate the problem using a binary search algorithm over multiple replications of the problem and find the expected value of 17.04 via simulation. The result would give an empirical distribution for the number of guesses needed to find the secret word as:
</p>

<center>
<img src="hist.jpg">
</center>

<p>
Below is R code implementing the binary search and repeating that process to find the expected value for the number of guesses.
</p>

<pre>
<code>
### Function to implement binary search
### k = secret number
### s = ordered sequence
### Function searches for secret number
### and reports number of iterations to find
binSearch <- function(k, s){ 
	s <- 1:s
	counter <- 1
		while(length(s) > 1){
			mid <- floor(median(s))
			if (k == mid){
			s <- k
			} else if (k < mid){
			s <- min(s):(mid-1)
			counter <- counter + 1
			} else {
			s <- (mid+1):max(s)
			counter <- counter + 1
		}
	}
	list("Value Found" = s, "Number of Iterations" = counter)
}

### Iterate over binSearch function 200,000 times to find expected value
k <- 200000
result <- numeric(k)
L <- 267751
for(i in 1:k){
	x <- sample(1:L,1)
	result[i] <- as.numeric(binSearch(x,L)[2][1])
}
mean(result)
</code>
</pre>

</h3>

<hr>
<center> <h1> Basketball Problem </h1> </center>

<h2> Problem Statement </h2>
<h3>
<p>
The basketball problem as stated <a href = "https://fivethirtyeight.com/features/can-you-reach-the-summit-first/" target = "blank"> here </a> is summarized as, "What is the probability that, on any given week, it’s possible to form two equal teams with everyone playing, where two towns are pitted against the third?"
</p>

<p>
<b> The general answer is \(\left(\frac{1}{N}\right)^3 \left[\frac{(N-1)^2 + (N-1)}{2}\right] \times 3\) where \(N\) is the number of individuals that show up from each of the three towns randomly. Then, the case with 5 players is a special case of this such that \(\left(\frac{1}{5}\right)^3 \left[\frac{(5-1)^2 + (5-1)}{2}\right] \times 3 = .24\). </b>
</p>
</h3>

<h2> Motivating Example </h2>
<h3>
<p>
It's easy to see the concept when N = 5 because the number of equal team combinations is small. In this example, we observe 30 possible ways in which equal teams could be created. For example, if 2 members show up from town \(x_1\), then we must have 1 from town \(x_2\) and 1 from town \(x_3\) (there is no option where 0 members show up from any town). So, write this as 2;1-1 as notation to mean that 2 members arrive from town \(x_1\) and then the equal team is created when 1 member arrives from town \(x_2\) and 1 more from town \(x_3\). Then, the other possible patterns in this example are 3;1-2, 3;2-1, 4;1-3, 4;2-2, 4;3-1, 5;1-4, 5;2-3, 5;3-2, and 5;4-1.
</p>
</h3>

<h2> Towards a Solution </h2>
<h3>

<p>
The motivating example shows a total of \(\frac{(N-1)^2 + (N-1)}{2}\) unique combinations for equal teams where town \(x_1\) is pitted against towns \(x_2\) and \(x_3\). But, since this can be arranged such that any town is the third town, we actually have \(\frac{(N-1)^2 + (N-1)}{2} \times 3\) possible equal team combinations.

Since we also assume each outcome is equally as likely (i.e., any number from 1 to 5 might show up), we have a probability of \(p = \left(\frac{1}{N}\right)^3\) to observe this outcome for each of the possible combinations to make equal teams. So in words, it's the probability of the outcome times the number of times an "equal teams" outcome can occur with \(N\) players from 3 towns.
</p>

<p>
We can "check" the analytic expression with a simulation. Some R code to run a simulation over \(K\) replications of the problem where \(N\) is the upper limit on the number of players that might arrive from any given town.
</p>
</h3>

<code>
### MC Answer<br>
K <- 1000000 <br>
N <- 5 # Change this to be any number of max players<br>
team1 <- sample(N,K, replace = TRUE)<br>
team2 <- sample(N,K, replace = TRUE)<br>
team3 <- sample(N,K, replace = TRUE)<br>
full <- as.data.frame(cbind(team1, team2, team3))<br>
indx <- apply(full, 1, function(x) which.max(x))<br>
result <- sapply(1:K, function(i) sum(full[i, -indx[i]]) == full[i,indx[i]])<br>
table(result)[2]/K<br>
### Analytic<br>
(1/N)^3 * ((N-1)^2 + (N-1))/2 * 3<br>
</code>

<hr>
<center> <h1> The Broken Ruler Problem </h1> </center>

<h2> Problem Statement </h2>
<h3>
<p>
The broken ruler problem as stated <a href = "https://fivethirtyeight.com/features/are-you-hip-enough-to-be-square/" target = "blank"> here </a> asks, "Recently, there was an issue with the production of foot-long rulers. It seems that each ruler was accidentally sliced at three random points along the ruler, resulting in four pieces. Looking on the bright side, that means there are now four times as many rulers — they just happen to have different lengths. On average, how long are the pieces that contain the 6-inch mark?"
</p>
</h3>

<h3>
<p>
The answer is 5.625. This submission provides an analytic solution and additionally a simulation-based approach.
</p>
</h3>

<h2> Motivating Example </h2>
<h3>

<p>
We can conceptualize the problem easily. Think about splitting the 12 inch ruler into two equal regions--a lower region below the 6 inch mark and an upper region above the 6 inch mark. Let \(R_1\) be the lower region, \(0 \leq R_1 < 6\) and let \(R_2\) be the upper region, \(6 < R_2 \leq 12\). Let each cut, \(x_i\) for \(i = {1,2,3}\), be an ordered random variable as \(0 < x_1 < x_2 < x_3 < 12\) and further assume the cuts are independent and uniformly distributed. Then there is a 50% chance that any given cut will fall into either \(R_1\) or \(R_2\).  
</p>

<p>
There are only two ways in which a cut can occur containing the 6 inch mark. One potential outcome occurs when \(x_i\) \(\forall \ i\) fall into one and only one region. Then, the length is measured from the ruler's edge to the first ordered point. A second way is when two cuts fall into one region and the remaining cut falls into the other. Then, the length is measured using the points where the 6 inch mark is interior to the cuts. For example, case 1 might be all points fall into \(R_1\) in which case the length is measured as \(L = 12 - x_3\). Or to illustrate case 2 we might observe two points in \(R_1\) and one point in \(R_2\). Then, the length is measured as \(L = x_3 - x_2\). 
</p>

<p>
All cuts are latent random variables and so we cannot know values for \(x_i\)--the preceding is just conceptual and motivates towards a solution. 
</p>

</h3>

<h2> Towards a Solution </h2>
<h3>

<p>
Order statistics have some nicely defined (and simple) expected values that work well for this scenario that are useful for solving this problem. It is specifically useful to know that \(E(\min(x_1, \dots, x_n ))= \frac{1}{N + 1}\). Then, we can define the expected value for the "long cut" to be:

$$
6 * (1 + E(\min(x_1,x_2,x_3)) = 6 \times (1 + 1/4) = 7.5.
$$ 

The probability that all three cuts fall above the 6" mark is \(.5^3\) = .125. Conversely, all cuts can fall below with the same probability, so long cuts will occur \(25\%\) of the time.
</p>

<p>
We can similarly define a "short cut" as:

$$
6 \times (E(\min(x_3,x_2) - E(x_1)) = 6 * ((1 + 1/3) - 1/2) =  8 - 3 = 5.
$$

The probability of this occuring is 1 - .25 = .75 (i.e., the converse of the long cut).
</p>

<p>
We then simply find the expected value via the weighted mean:

$$
E(X) = .25 \times 7.5 + .75 \times 5 = 5.625. 
$$
</p>

<p>
To "verify" lets explore using a simulation-based method. Take 3 random draws for \(x_i ~ U[0,12]\) and sort them by increasing value to represent the ordering of \(x_1, x_2\), and \(x_3\). These can be treated as the cut locations on the ruler occuring at three randomly placed locations between 0 and 12 giving us a simulated "broken ruler" with 4 segments.

Now, search to find which of the four resulting segments contains the 6 inch mark and measure the length of this segment as \(L = x_i - x_{i-1}\). Replicate this process \(K\) times, yielding a vector of lengths, \(L = {L_1, L_2, \ldots, L_k}\) and find the mean over the vector of simulated possible outcomes. The R code below implements this process for generating the data and finding the mean.  
</p>

If we examine the empirical distribution of all simulated outcomes, we see a "shark fin" looking distribution of potential outcomes.

<center>
<img src="ruler.jpg">
</center>

<pre>
<code>
K = 10000000 #Number of replicates. Change to a lower number for speed
result <- numeric(K)
for(i in 1:K){
	### Randomly cut a ruler into 4 pieces (three random cuts)
	cuts <- c(0, sort(runif(3, 0,12)), 12)

	### Find which piece contains 6" mark
	pos <- min(which(TRUE == (6 <= cuts)))

	### Measure length of piece containing the 6" mark
	result[i] <- cuts[pos]-cuts[(pos-1)]
}

mean(result)
5.62484
</pre>
</code>






</body>

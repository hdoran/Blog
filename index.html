---
layout: default
---

<body>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!--<center> <h1>Statistics, Psychometrics, Games</h1> </center>
<center> <h3>Harold Doran</h3> </center> -->

<center> <h1> Dictionary Problem </h1> </center>

<h2> Problem Statement </h2>
<h3>
<p>
The dictionary problem as stated <a href = "https://fivethirtyeight.com/features/can-you-break-a-very-expensive-centrifuge/" target = "blank"> here </a> is summarized as:

"Each secret word is randomly chosen from a dictionary with exactly 267,751 entries. If you have this dictionary memorized, and play the game as efficiently as possible, how many guesses should you expect to make to guess the secret word?" <b> The answer is 17.04 with a maximum number of required guesses being 19. </b>
</p>

</h3>

<h2> Motivating Example </h2>
<h3>
<p>
The solution is motivated by a simple example using a <a href = "https://en.wikipedia.org/wiki/Binary_search_algorithm" target="_blank"> binary search algorithm </a> to consider how we might work efficiently. To illustrate, I pick a random number from 1 to 15 and ask you to guess the number I am thinking. I will tell you if it's higher, lower, or correct. You first guess the midpoint, 8, which has a \(\frac{1}{15}\) chance of being correct. If the number is higher you can eliminate numbers 1 to 8 (or vice versa if the number is lower) and guess two has a \(\frac{1}{7}\) chance of being correct by focusing on the new region of the sequence (i.e., numbers 9 through 15). If a guess 3 is needed, find the midpoint in the remaining sequence and the success probability becomes \(\frac{1}{3}\). Last, guess 4 (if needed) has only one remaining possible choice, hence the success probability at this point is 1. Using this strategy with a sequence of size 15, you would need a maximum of 4 attempts to identify the number with certainty.
</p>

<p>
So, by iteratively halving the sequence and reducing the search space in the region where the number exists, we continue to improve the probability of success until we ultimately reach a point of certainty. This illustrates a way to work efficiently and a model for estimating the maximum number of guesses we would need to find a solution. However, we won't always need the maximum number of guesses as other values less than the maximum have non-zero probabilities, but this helps conceptualize the problem to work towards a solution for the expected value.
</p>

<p>
Combining these pieces of information, we can find the expected value for the number of guesses, \(E(G)\), by using the probabilities of being right or wrong at each possible guess, 1 through the maximum. In this example, we can write:

$$
E(G) = 1 \cdot \frac{1}{15} + 2 \cdot \frac{14}{15}\frac{1}{7} + 3 \cdot \frac{14}{15}\frac{6}{7}\frac{1}{3} + 4 \cdot \frac{14}{15}\frac{6}{7}\frac{2}{3}1 = 3.266
$$

This example shows that piecing this together requires knowing:
<ul>
	<li> The maximum number of guesses needed
	<li> The probability of being right at each guess
	<li> The accumulated probabilities of being wrong for all guesses prior to the \(n\)th guess
</ul>
</p>

To establish a little notation for the preceding example, let \(\Pr(x=1|g_n)\) denote the success probability at the \(n\)th guess and let \(\Pr(x=0|g_n)\) denote the probability of being wrong at the \(n\)th guess. Then the expected value for the number of guesses in this example can be written as:

$$
\begin{split}
E(G) & = 1 \cdot \Pr(x=1|g_1) \\ 
	& +  2 \cdot \Pr(x=0|g_1)\Pr(x=1|g_2) \\  
	& + 3 \cdot \Pr(x=0|g_1)\Pr(x=0|g_2)\Pr(x=1|g_3) \\ 
	& + 4 \cdot \Pr(x=0|g_1)\Pr(x=0|g_2)\Pr(x=0|g_3)\Pr(x=1|g_4)
\end{split}
$$

<h2> Towards a Solution </h2>
<h3>

<p>
Knowing that our success probability tends to 1 using this strategy, finding a general solution requires building a model that makes use of this efficient strategy. For completeness, first find the maximum number of times a sequence of size \(k\) can be halved \(L\): 

$$
L = \textrm{floor}\left(\frac{\log(k)}{\log(2)}\right)
$$ 

and then generally the maximum number of guesses needed to locate the correct answer in a sequence of size \(k\) is \(N = 1 + L\), or initial guess plus remaining number of times the sequence can be halved. Then, generalizing to find the expected value over an arbitrary sequence of length \(k\):

$$
E(G) = \Pr(x=1|g_1) + \sum_{n=2}^N \left(n \cdot \Pr(x=1|g_n) \prod_{j \in a}\Pr(x=0|g_j)\right)
$$

where the notation \(j \in a\) is used to mean the accumulated set of incorrect probabilities preceding the \(n\)th guess.

</p>

<p>
Applying this to the dictionary problem with a dictionary consisting of 267,751 words yields an expected <b> maximum </b> number of guesses:

$$
\textrm{floor}\left(\frac{\log(267751)}{\log(2)}\right) + 1 = 19.
$$ 
</p>

<p>
However, guessing the secret word could happen in fewer than 19 guesses. We can apply the expression above to find \(E(G) = 17.04\). Additionally, we can simulate the problem using a binary search algorithm over multiple replications of the problem and find the expected value of 17.04 via simulation. The result would give an empirical distribution for the number of guesses needed to find the secret word as:
</p>

<center>
<img src="hist.jpg">
</center>

<p>
Below is R code implementing the binary search and repeating that process to find the expected value for the number of guesses.
</p>

<pre>
<code>
### Function to implement binary search
### k = secret number
### s = ordered sequence
### Function searches for secret number
### and reports number of iterations to find
binSearch <- function(k, s){ 
	s <- 1:s
	counter <- 1
		while(length(s) > 1){
			mid <- floor(median(s))
			if (k == mid){
			s <- k
			} else if (k < mid){
			s <- min(s):(mid-1)
			counter <- counter + 1
			} else {
			s <- (mid+1):max(s)
			counter <- counter + 1
		}
	}
	list("Value Found" = s, "Number of Iterations" = counter)
}

### Iterate over binSearch function 200,000 times to find expected value
k <- 200000
result <- numeric(k)
L <- 267751
for(i in 1:k){
	x <- sample(1:L,1)
	result[i] <- as.numeric(binSearch(x,L)[2][1])
}
mean(result)
</code>
</pre>

</h3>

<hr>
<center> <h1> Basketball Problem </h1> </center>

<h2> Problem Statement </h2>
<h3>
<p>
The basketball problem as stated <a href = "https://fivethirtyeight.com/features/can-you-reach-the-summit-first/" target = "blank"> here </a> is summarized as, "What is the probability that, on any given week, itâ€™s possible to form two equal teams with everyone playing, where two towns are pitted against the third?"</p>

<p>
<b> The general answer is \(\left(\frac{1}{N}\right)^3 \left[\frac{(N-1)^2 + (N-1)}{2}\right] \times 3\) where \(N\) is the number of individuals that show up from each of the three towns randomly. Then, the case with 5 players is a special case of this such that \(\left(\frac{1}{5}\right)^3 \left[\frac{(5-1)^2 + (5-1)}{2}\right] \times 3 = .24\). </b>
</p>

</h3>

<h2> Motivating Example </h2>
<h3>
<p>
It's easy to see the concept when N = 5 because the number of equal team combinations is small. In this example, we observe 30 possible ways in which equal teams could be created. For example, if 2 members show up from town \(x_1\), then we must have 1 from town \(x_2\) and 1 from town \(x_3\) (there is no option where 0 members show up from any town). So, write this as 2;1-1 as notation to mean that 2 members arrive from town \(x_1\) and then the equal team is created when 1 member arrives from town \(x_2\) and 1 more from town \(x_3\). Then, the other possible patterns in this example are 3;1-2, 3;2-1, 4;1-3, 4;2-2, 4;3-1, 5;1-4, 5;2-3, 5;3-2, and 5;4-1.
</p>

<h2> Towards a Solution </h2>
<h3>

<p>
The motivating example shows a total of \(\frac{(N-1)^2 + (N-1)}{2}\) unique combinations for equal teams where town \(x_1\) is pitted against towns \(x_2\) and \(x_3\). But, since this can be arranged such that any town is the third town, we actually have \(\frac{(N-1)^2 + (N-1)}{2} \times 3\) possible equal team combinations.

Since we also assume each outcome is equally as likely (i.e., any number from 1 to 5 might show up), we have a probability of \(p = \left(\frac{1}{N}\right)^3\) to observe this outcome for each of the possible combinations to make equal teams. So in words, it's the probability of the outcome times the number of times an "equal teams" outcome can occur with \(N\) players from 3 towns.
</p>

<p>
We can "check" the analytic expression with a simulation. Some R code to run a simulation over \(K\) replications of the problem where \(N\) is the upper limit on the number of players that might arrive from any given town.
</p>
</h3>

<code>
### MC Answer<br>
K <- 1000000 <br>
N <- 5 # Change this to be any number of max players<br>
team1 <- sample(N,K, replace = TRUE)<br>
team2 <- sample(N,K, replace = TRUE)<br>
team3 <- sample(N,K, replace = TRUE)<br>
full <- as.data.frame(cbind(team1, team2, team3))<br>
indx <- apply(full, 1, function(x) which.max(x))<br>
result <- sapply(1:K, function(i) sum(full[i, -indx[i]]) == full[i,indx[i]])<br>
table(result)[2]/K<br>
### Analytic<br>
(1/N)^3 * ((N-1)^2 + (N-1))/2 * 3<br>
</code>


</body>
